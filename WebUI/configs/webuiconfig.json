{
    "Name": "Keras-llm-Robot",
    "Version": "1.0.0.",
    "CreateDate": "11//07//2023 20:16PM",
    "Description": "KERAS LLM Chat Robot",
    "WebConfig": {
        "ShowRunningStatus": false,
        "SaveChatHistory": false
    },
    "ModelConfig": {
        "OnlineModel": {
            "openai-api": {
                "modellist": [
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-16k",
                    "gpt-4",
                    "gpt-4-32k",
                    "gpt-4-1106-preview",
                    "gpt-4-vision-preview"
                ],
                "baseurl": "https://api.openai.com/v1",
                "load_type": "cloud",
                "apiversion": "",
                "preset": "default",
                "apikey": "[Your Key]",
                "apiproxy": "[Private Proxy]",
                "provider": "OpenAI"
            },
            "google-api": {
                "modellist": [
                    "gemini-pro",
                    "gemini-pro-vision",
                    "chat-bison-001",
                    "text-bison-001"
                ],
                "baseurl": "",
                "load_type": "cloud",
                "apiversion": "",
                "preset": "default",
                "apikey": "[Your Key]",
                "apiproxy": "[Private Proxy]",
                "provider": "GoogleCloud"
            },
            "azure-api": {
                "modellist": [],
                "baseurl": "",
                "load_type": "cloud",
                "apiversion": "",
                "preset": "default",
                "apikey": "[Your Key]",
                "apiproxy": "[Private Proxy]",
                "provider": "AzureCloud"
            }
        },
        "EmbeddingModel": {
            "bge-large-en-v1.5": {
                "path": "models/embeddings/bge-large-en-v1.5",
                "Huggingface": "BAAI/bge-large-en-v1.5"
            },
            "bge-large-zh-v1.5": {
                "path": "models/embeddings/bge-large-zh-v1.5",
                "Huggingface": "BAAI/bge-large-zh-v1.5"
            },
            "m3e-small": {
                "path": "models/embeddings/m3e-small",
                "Huggingface": "moka-ai/m3e-small"
            },
            "m3e-base": {
                "path": "models/embeddings/m3e-base",
                "Huggingface": "moka-ai/m3e-base"
            },
            "m3e-large": {
                "path": "models/embeddings/m3e-large",
                "Huggingface": "moka-ai/m3e-large"
            },
            "bge-small-en-v1.5": {
                "path": "models/embeddings/bge-small-en-v1.5",
                "Huggingface": "BAAI/bge-small-en-v1.5"
            },
            "bge-base-en-v1.5": {
                "path": "models/embeddings/bge-base-en-v1.5",
                "Huggingface": "BAAI/bge-base-en-v1.5"
            },
            "bge-small-zh-v1.5": {
                "path": "models/embeddings/bge-small-zh-v1.5",
                "Huggingface": "BAAI/bge-small-zh-v1.5"
            },
            "bge-base-zh-v1.5": {
                "path": "models/embeddings/bge-base-zh-v1.5",
                "Huggingface": "BAAI/bge-base-zh-v1.5"
            },
            "text-embedding-ada-002": {
                "path": "",
                "apikey": "[Your Key]",
                "provider": "OpenAI"
            },
            "embedding-gecko-001": {
                "path": "",
                "apikey": "[Your Key]",
                "provider": "GoogleCloud"
            },
            "embedding-001": {
                "path": "",
                "apikey": "[Your Key]",
                "provider": "GoogleCloud"
            }
        },
        "RerankerModel": {
            "bge-reranker-base": {
                "path": "models/reranker/bge-reranker-base",
                "Huggingface": "BAAI/bge-reranker-base"
            },
            "bge-reranker-large": {
                "path": "models/reranker/bge-reranker-large",
                "Huggingface": "BAAI/bge-reranker-large"
            }
        },
        "ImageRecognition": {
            "blip-image-captioning-large": {
                "type": "local",
                "path": "models/imagerecognition/blip-image-captioning-large",
                "device": "cpu",
                "loadbits": 16,
                "Huggingface": "Salesforce/blip-image-captioning-large"
            }
        },
        "ImageGeneration": {
            "OpenDalleV1.1": {
                "type": "local",
                "path": "models/imagegeneration/OpenDalleV1.1",
                "device": "auto",
                "loadbits": 16,
                "Huggingface": "dataautogpt3/OpenDalleV1.1",
                "config": {
                    "seed": -1,
                    "torch_compile": false,
                    "cpu_offload": false,
                    "refiner": true
                }
            },
            "ProteusV0.2": {
                "type": "local",
                "path": "models/imagegeneration/ProteusV0.2",
                "device": "auto",
                "loadbits": 16,
                "Huggingface": "dataautogpt3/ProteusV0.2",
                "config": {
                    "seed": 5,
                    "torch_compile": false,
                    "cpu_offload": false,
                    "refiner": true
                }
            }
        },
        "VtoTModel": {
            "whisper-base": {
                "type": "local",
                "path": "models/voices/whisper-base",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-base"
            },
            "whisper-medium": {
                "type": "local",
                "path": "models/voices/whisper-medium",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-medium"
            },
            "whisper-large-v3": {
                "type": "local",
                "path": "models/voices/whisper-large-v3",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-large-v3"
            },
            "faster-whisper-large-v3": {
                "type": "local",
                "path": "models/voices/faster-whisper-large-v3",
                "device": "gpu",
                "loadbits": 8,
                "Huggingface": "bababababooey/faster-whisper-large-v3"
            },
            "AzureVoiceService": {
                "type": "cloud",
                "voice_key": "[Your Key]",
                "voice_region": "[Your Region]",
                "provider": "AzureCloud",
                "CloudTemplates": "AzureVoiceTemplate"
            }
        },
        "TtoVModel": {
            "XTTS-v2": {
                "type": "local",
                "path": "models/voices/XTTS-v2",
                "device": "gpu",
                "loadbits": 16,
                "synthesis": {
                    "en-US": {
                        "male": [
                            "en_male-v1",
                            "en_male-v2"
                        ],
                        "female": [
                            "en_female-v1",
                            "en_female-v2"
                        ],
                        "non-binary": []
                    },
                    "zh-CN": {
                        "male": [
                            "zh-cn_male-v1",
                            "zh-cn_male-v2"
                        ],
                        "female": [
                            "zh-cn_female-v1",
                            "zh-cn_female-v2"
                        ],
                        "non-binary": []
                    }
                },
                "CloudTemplates": "",
                "Huggingface": "coqui/XTTS-v2"
            },
            "AzureSpeechService": {
                "type": "cloud",
                "speech_key": "[Your Key]",
                "speech_region": "[Your Region]",
                "provider": "AzureCloud",
                "synthesis": {
                    "en-US": {
                        "male": [
                            "en-US-GuyNeural",
                            "en-US-DavisNeural",
                            "en-US-AndrewNeural",
                            "en-US-BrandonNeural",
                            "en-US-BrianNeural",
                            "en-US-ChristopherNeural",
                            "en-US-EricNeural",
                            "en-US-JacobNeural",
                            "en-US-JasonNeural",
                            "en-US-RogerNeural",
                            "en-US-SteffanNeural",
                            "en-US-TonyNeural",
                            "en-US-AIGenerate1Neural",
                            "en-US-RyanMultilingualNeural"
                        ],
                        "female": [
                            "en-US-JennyMultilingualNeural",
                            "en-US-JennyNeural",
                            "en-US-AriaNeural",
                            "en-US-AmberNeural",
                            "en-US-AshleyNeural",
                            "en-US-CoraNeural",
                            "en-US-ElizabethNeural",
                            "en-US-EmmaNeural",
                            "en-US-JaneNeural",
                            "en-US-MichelleNeural",
                            "en-US-MonicaNeural",
                            "en-US-NancyNeural",
                            "en-US-SaraNeural",
                            "en-US-AIGenerate2Neural",
                            "en-US-JennyMultilingualV2Neural"
                        ],
                        "non-binary": [
                            "en-US-BlueNeural"
                        ]
                    },
                    "zh-CN": {
                        "male": [
                            "zh-CN-YunxiNeural",
                            "zh-CN-YunjianNeural",
                            "zh-CN-YunyangNeural",
                            "zh-CN-YunfengNeural",
                            "zh-CN-YunhaoNeural",
                            "zh-CN-YunxiaNeural",
                            "zh-CN-YunyeNeural",
                            "zh-CN-YunzeNeural",
                            "zh-CN-YunjieNeural"
                        ],
                        "female": [
                            "zh-CN-XiaoxiaoNeural",
                            "zh-CN-XiaoyiNeural",
                            "zh-CN-XiaochenNeural",
                            "zh-CN-XiaohanNeural",
                            "zh-CN-XiaomengNeural",
                            "zh-CN-XiaomoNeural",
                            "zh-CN-XiaoqiuNeural",
                            "zh-CN-XiaoruiNeural",
                            "zh-CN-XiaoshuangNeural",
                            "zh-CN-XiaoxuanNeural",
                            "zh-CN-XiaoyanNeural",
                            "zh-CN-XiaoyouNeural",
                            "zh-CN-XiaozhenNeural",
                            "zh-CN-XiaorouNeural"
                        ],
                        "non-binary": []
                    },
                    "yue-CN": {
                        "male": [
                            "yue-CN-YunSongNeural"
                        ],
                        "female": [
                            "yue-CN-XiaoMinNeural"
                        ],
                        "non-binary": []
                    },
                    "zh-TW": {
                        "male": [
                            "zh-TW-YunJheNeural"
                        ],
                        "female": [
                            "zh-TW-HsiaoChenNeural",
                            "zh-TW-HsiaoYuNeural"
                        ],
                        "non-binary": []
                    },
                    "en-CA": {
                        "male": [
                            "en-CA-LiamNeural"
                        ],
                        "female": [
                            "en-CA-ClaraNeural"
                        ],
                        "non-binary": []
                    },
                    "en-AU": {
                        "male": [
                            "en-AU-WilliamNeural",
                            "en-AU-DarrenNeural",
                            "en-AU-DuncanNeural",
                            "en-AU-KenNeural",
                            "en-AU-NeilNeural",
                            "en-AU-TimNeural"
                        ],
                        "female": [
                            "en-AU-NatashaNeural",
                            "en-AU-AnnetteNeural",
                            "en-AU-CarlyNeural",
                            "en-AU-ElsieNeural",
                            "en-AU-FreyaNeural",
                            "en-AU-JoanneNeural",
                            "en-AU-KimNeural",
                            "en-AU-TinaNeural"
                        ],
                        "non-binary": []
                    },
                    "de-DE": {
                        "male": [
                            "de-DE-ConradNeural",
                            "de-DE-BerndNeural",
                            "de-DE-ChristophNeural",
                            "de-DE-KasperNeural",
                            "de-DE-KillianNeural",
                            "de-DE-KlausNeural",
                            "de-DE-RalfNeural"
                        ],
                        "female": [
                            "de-DE-KatjaNeural",
                            "de-DE-AmalaNeural",
                            "de-DE-ElkeNeural",
                            "de-DE-GiselaNeural",
                            "de-DE-KlarissaNeural",
                            "de-DE-LouisaNeural",
                            "de-DE-MajaNeural",
                            "de-DE-SeraphinaNeural",
                            "de-DE-TanjaNeural"
                        ],
                        "non-binary": []
                    },
                    "fr-FR": {
                        "male": [
                            "fr-FR-HenriNeural",
                            "fr-FR-AlainNeural",
                            "fr-FR-ClaudeNeural",
                            "fr-FR-JeromeNeural",
                            "fr-FR-MauriceNeural",
                            "fr-FR-YvesNeural"
                        ],
                        "female": [
                            "fr-FR-DeniseNeural",
                            "fr-FR-BrigitteNeural",
                            "fr-FR-CelesteNeural",
                            "fr-FR-CoralieNeural",
                            "fr-FR-EloiseNeural",
                            "fr-FR-JacquelineNeural",
                            "fr-FR-JosephineNeural",
                            "fr-FR-VivienneNeural",
                            "fr-FR-YvetteNeural"
                        ],
                        "non-binary": []
                    },
                    "fr-CA": {
                        "male": [
                            "fr-CA-JeanNeural",
                            "fr-CA-AntoineNeural",
                            "fr-CA-ThierryNeural"
                        ],
                        "female": [
                            "fr-CA-SylvieNeural"
                        ],
                        "non-binary": []
                    },
                    "ko-KR": {
                        "male": [
                            "ko-KR-InJoonNeural",
                            "ko-KR-BongJinNeural",
                            "ko-KR-GookMinNeural",
                            "ko-KR-HyunsuNeural"
                        ],
                        "female": [
                            "ko-KR-SunHiNeural",
                            "ko-KR-JiMinNeural",
                            "ko-KR-SeoHyeonNeural",
                            "ko-KR-SoonBokNeural",
                            "ko-KR-YuJinNeural"
                        ],
                        "non-binary": []
                    },
                    "ja-JP": {
                        "male": [
                            "ja-JP-KeitaNeural",
                            "ja-JP-DaichiNeural",
                            "ja-JP-NaokiNeural"
                        ],
                        "female": [
                            "ja-JP-NanamiNeural",
                            "ja-JP-AoiNeural",
                            "ja-JP-MayuNeural",
                            "ja-JP-ShioriNeural"
                        ],
                        "non-binary": []
                    }
                },
                "CloudTemplates": "AzureSpeechTemplate"
            },
            "OpenAISpeechService": {
                "type": "cloud",
                "speech_key": "[Your Key]",
                "speech_region": "[Your Region]",
                "provider": "OpenAICloud",
                "synthesis": {
                    "en-US": {
                        "male": [
                            "alloy",
                            "echo",
                            "fable",
                            "onyx"
                        ],
                        "female": [
                            "nova",
                            "shimmer"
                        ],
                        "non-binary": [
                            ""
                        ]
                    }
                },
                "CloudTemplates": "OpenAISpeechTemplate"
            }
        },
        "LocalModel": {
            "LLM Model": {
                "3B Model": {
                    "TinyLlama-1.1B-Chat-v1.0": {
                        "path": "models/llm/TinyLlama-1.1B-Chat-v1.0",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
                    },
                    "fastchat-t5-3b-v1.0": {
                        "path": "models/llm/fastchat-t5-3b-v1.0",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "lmsys/fastchat-t5-3b-v1.0"
                    },
                    "gemma-2b": {
                        "path": "models/llm/gemma-2b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "google/gemma-2b"
                    },
                    "gemma-2b-it": {
                        "path": "models/llm/gemma-2b-it",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "google/gemma-2b-it"
                    }
                },
                "7B Model": {
                    "llama-2-7b-hf": {
                        "path": "models/llm/llama-2-7b-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/llama-2-7b-hf"
                    },
                    "llama-2-7b-chat-hf": {
                        "path": "models/llm/Llama-2-7b-chat-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/Llama-2-7b-chat-hf"
                    },
                    "chatglm2-6b": {
                        "path": "models/llm/chatglm2-6b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "THUDM/chatglm2-6b"
                    },
                    "chatglm2-6b-32k": {
                        "path": "models/llm/chatglm2-6b-32k",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "THUDM/chatglm2-6b-32k"
                    },
                    "chatglm3-6b": {
                        "path": "models/llm/chatglm3-6b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "THUDM/chatglm3-6b"
                    },
                    "tigerbot-7b-chat": {
                        "path": "models/llm/tigerbot-7b-chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "TigerResearch/tigerbot-7b-chat"
                    },
                    "openchat_3.5": {
                        "path": "models/llm/openchat_3.5",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "openchat/openchat_3.5"
                    },
                    "openchat-3.5-1210": {
                        "path": "models/llm/openchat-3.5-1210",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "openchat/openchat-3.5-1210"
                    },
                    "openchat-3.5-0106": {
                        "path": "models/llm/openchat-3.5-0106",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "openchat/openchat-3.5-0106"
                    },
                    "Qwen-7B-Chat-Int4": {
                        "path": "models/llm/Qwen-7B-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "Qwen/Qwen-7B-Chat-Int4"
                    },
                    "fuyu-8b": {
                        "path": "models/llm/fuyu-8b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "adept/fuyu-8b"
                    },
                    "Yi-6B-Chat-4bits": {
                        "path": "models/llm/Yi-6B-Chat-4bits",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "01-ai/Yi-6B-Chat-4bits"
                    },
                    "neural-chat-7b-v3-1": {
                        "path": "models/llm/neural-chat-7b-v3-1",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "Intel/neural-chat-7b-v3-1"
                    },
                    "Mistral-7B-Instruct-v0.2": {
                        "path": "models/llm/Mistral-7B-Instruct-v0.2",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "mistralai/Mistral-7B-Instruct-v0.2"
                    },
                    "gemma-7b": {
                        "path": "models/llm/gemma-7b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "google/gemma-7b"
                    },
                    "gemma-7b-it": {
                        "path": "models/llm/gemma-7b-it",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "google/gemma-7b-it"
                    }
                },
                "13B Model": {
                    "llama-2-13b-hf": {
                        "path": "models/llm/llama-2-13b-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/llama-2-13b-hf"
                    },
                    "llama-2-13b-chat-hf": {
                        "path": "models/llm/Llama-2-13b-chat-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/Llama-2-13b-chat-hf"
                    },
                    "tigerbot-13b-chat": {
                        "path": "models/llm/tigerbot-13b-chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "TigerResearch/tigerbot-13b-chat"
                    },
                    "Qwen-14B-Chat": {
                        "path": "models/llm/Qwen-14B-Chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "Qwen/Qwen-14B-Chat"
                    },
                    "Qwen-14B-Chat-Int4": {
                        "path": "models/llm/Qwen-14B-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "Qwen/Qwen-14B-Chat-Int4"
                    }
                },
                "34B Model": {
                    "Yi-34B-Chat-4bits": {
                        "path": "models/llm/Yi-34B-Chat-4bits",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "01-ai/Yi-34B-Chat-4bits"
                    }
                },
                "70B Model": {
                    "llama-2-70b-hf": {
                        "path": "models/llm/llama-2-70b-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 8,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/llama-2-70b-hf"
                    },
                    "llama-2-70b-chat-hf": {
                        "path": "models/llm/Llama-2-70b-chat-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 8,
                        "loadbits": 8,
                        "preset": "default",
                        "load_type": "fastchat",
                        "Huggingface": "meta-llama/Llama-2-70b-chat-hf"
                    }
                }
            },
            "Multimodal Model": {
                "Vision Chat Model": {
                    "cogvlm-chat-hf": {
                        "path": "models/multimodal/image-chat/cogvlm-chat-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "causallm",
                        "Huggingface": "THUDM/cogvlm-chat-hf"
                    },
                    "Qwen-VL-Chat": {
                        "path": "models/multimodal/image-chat/Qwen-VL-Chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 4,
                        "preset": "default",
                        "load_type": "causallm",
                        "Huggingface": "Qwen/Qwen-VL-Chat"
                    },
                    "Qwen-VL-Chat-Int4": {
                        "path": "models/multimodal/image-chat/Qwen-VL-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 4,
                        "preset": "default",
                        "load_type": "causallm",
                        "Huggingface": "Qwen/Qwen-VL-Chat-Int4"
                    },
                    "stable-video-diffusion-img2vid": {
                        "path": "models/multimodal/image-chat/stable-video-diffusion-img2vid",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "vdiffusion",
                        "Huggingface": "stabilityai/stable-video-diffusion-img2vid"
                    },
                    "stable-video-diffusion-img2vid-xt": {
                        "path": "models/multimodal/image-chat/stable-video-diffusion-img2vid-xt",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "vdiffusion",
                        "Huggingface": "stabilityai/stable-video-diffusion-img2vid-xt"
                    }
                },
                "Voice Chat Model": {
                    "Qwen-Audio-Chat": {
                        "path": "models/multimodal/voice-chat/Qwen-Audio-Chat",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "causallm",
                        "Huggingface": "Qwen/Qwen-Audio-Chat"
                    }
                },
                "Video Chat Model": {}
            },
            "Code Model": {
                "3B Model": {
                    "stable-code-3b": {
                        "path": "models/llm/stable-code-3b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "causallm",
                        "Huggingface": "stabilityai/stable-code-3b"
                    }
                },
                "7B Model": {
                    "CodeLlama-7b-Python-hf": {
                        "path": "models/llm/CodeLlama-7b-Python-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "llama",
                        "Huggingface": "codellama/CodeLlama-7b-Python-hf"
                    },
                    "CodeLlama-7b-Instruct-hf": {
                        "path": "models/llm/CodeLlama-7b-Instruct-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "llama",
                        "Huggingface": "codellama/CodeLlama-7b-Instruct-hf"
                    }
                },
                "13B Model": {
                    "CodeLlama-13b-Python-hf": {
                        "path": "models/llm/CodeLlama-13b-Python-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "llama",
                        "Huggingface": "codellama/CodeLlama-13b-Python-hf"
                    },
                    "CodeLlama-13b-Instruct-hf": {
                        "path": "models/llm/CodeLlama-13b-Instruct-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "llama",
                        "Huggingface": "codellama/CodeLlama-13b-Instruct-hf"
                    }
                },
                "34B Model": {},
                "70B Model": {}
            },
            "Special Model": {
                "3B Model": {
                    "phi-2-gguf": {
                        "path": "models/llm/phi-2-GGUF",
                        "device": "auto",
                        "maxmemory": 6,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "Phi 2",
                        "load_type": "llamacpp",
                        "Huggingface": "TheBloke/phi-2-GGUF"
                    },
                    "phi-2": {
                        "path": "models/llm/phi-2",
                        "device": "auto",
                        "maxmemory": 10,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "Phi 2",
                        "load_type": "pipeline",
                        "Huggingface": "microsoft/phi-2"
                    }
                },
                "7B Model": {
                    "Yi-6B-Chat-gguf": {
                        "path": "models/llm/Yi-6B-Chat-GGUF",
                        "device": "cpu",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "ChatML",
                        "load_type": "llamacpp",
                        "Huggingface": "TheBloke/Yi-6B-Chat-GGUF"
                    },
                    "OpenHermes-2.5-Mistral-7B": {
                        "path": "models/llm/OpenHermes-2.5-Mistral-7B",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "ChatML",
                        "load_type": "pipeline",
                        "Huggingface": "teknium/OpenHermes-2.5-Mistral-7B"
                    }
                },
                "13B Model": {},
                "34B Model": {
                    "Yi-34B-Chat-gguf": {
                        "path": "models/llm/Yi-34B-Chat-GGUF",
                        "device": "cpu",
                        "maxmemory": 50,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "default",
                        "load_type": "llamacpp",
                        "Huggingface": "TheBloke/Yi-34B-Chat-GGUF"
                    },
                    "Mixtral-8x7B-v0.1-gguf": {
                        "path": "models/llm/Mixtral-8x7B-v0.1-GGUF",
                        "device": "cpu",
                        "maxmemory": 50,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "preset": "Mistral Instruct",
                        "load_type": "llamacpp",
                        "Huggingface": "TheBloke/Mixtral-8x7B-v0.1-GGUF"
                    }
                },
                "70B Model": {}
            }
        }
    },
    "ServerConfig": {
        "default_host_ip": "0.0.0.0",
        "default_timeout": 300,
        "load_timeout": 120,
        "release_timeout": 60,
        "webui_server": {
            "host": "default_host_ip",
            "port": 8818
        },
        "fastchat_controller": {
            "host": "default_host_ip",
            "port": 20001,
            "dispatch_method": "shortest_queue"
        },
        "api_server": {
            "host": "default_host_ip",
            "port": 8819
        },
        "fastchat_openai_api": {
            "host": "default_host_ip",
            "port": 20000
        },
        "vtot_model_worker": {
            "host": "default_host_ip",
            "port": 20002,
            "device": "auto"
        },
        "ttov_model_worker": {
            "host": "default_host_ip",
            "port": 20003,
            "device": "auto"
        },
        "image_recognition_worker": {
            "host": "default_host_ip",
            "port": 20004,
            "device": "auto"
        },
        "image_generation_worker": {
            "host": "default_host_ip",
            "port": 20005,
            "device": "auto"
        },
        "fastchat_model_worker": {
            "default": {
                "host": "default_host_ip",
                "port": 20010,
                "device": "auto",
                "vllm_enable": false
            }
        }
    },
    "ChatConfiguration": {
        "dialogue_turns": 5,
        "temperature": 0.7,
        "top_p": 0.9,
        "typical_p": 1.0,
        "top_a": 1.0,
        "tfs": 1.0,
        "epsilon_cutoff": 0.0,
        "eta_cutoff": 0.0,
        "diversity_penalty": 0.0,
        "no_repeat_ngram_size": 0,
        "do_samples": false,
        "tokens_length": {
            "cur": 1000,
            "min": 0,
            "max": 5000,
            "step": 10
        },
        "seed": {
            "cur": -1,
            "min": -1,
            "max": 1000
        },
        "top_k": {
            "cur": 50,
            "min": 0,
            "max": 200,
            "step": 1
        },
        "repetition_penalty": {
            "cur": 1.15,
            "min": 0.0,
            "max": 3.0,
            "step": 0.05
        },
        "encoder_repetition_penalty": {
            "cur": 1.15,
            "min": 0.0,
            "max": 3.0,
            "step": 0.05
        },
        "length_penalty": {
            "cur": 1,
            "min": 0,
            "max": 2,
            "step": 1
        },
        "guidance_scale": {
            "cur": 1,
            "min": 0,
            "max": 2,
            "step": 1
        }
    },
    "QuantizationConfiguration": {},
    "Fine-Tunning": {},
    "SearchEngine": {
        "duckduckgo": {
            "search_url": "",
            "api_key": ""
        },
        "bing": {
            "search_url": "https://api.bing.microsoft.com/v7.0/search",
            "api_key": "YOUR_API_KEY"
        },
        "metaphor": {
            "search_url": "",
            "api_key": "YOUR_API_KEY"
        },
        "top_k": 5
    },
    "CodeInterpreter": {
        "Keras Interpreter": {
            "custom_instructions": "[default]",
            "system_message": "[default]"
        },
        "Open Interpreter": {
            "custom_instructions": "[default]",
            "system_message": "[default]"
        },
        "offline": false,
        "auto_run": false,
        "safe_mode": false
    },
    "PromptTemplates": {}
}