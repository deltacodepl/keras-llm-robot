{
    "Name": "Keras-llm-Robot",
    "Version": "1.0.0.",
    "CreateDate": "11//07//2023 20:16PM",
    "Description": "KERAS LLM Chat Robot",
    "WebConfig": {
        "ShowRunningStatus": false,
        "SaveChatHistory": false
    },
    "ModelConfig": {
        "OnlineModel": {
            "openai-api": {
                "modellist": [
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-16k",
                    "gpt-4",
                    "gpt-4-1106-preview",
                    "gpt-4-vision-preview"
                ],
                "baseurl": "https://api.openai.com/v1",
                "apiversion": "",
                "apikey": "",
                "apiproxy": ""
            },
            "azure-api": {
                "modellist": [],
                "resourcename": "",
                "apiversion": "",
                "apikey": "",
                "apiproxy": "",
                "provider": "AzureWorker"
            }
        },
        "EmbeddingModel": {
            "jina-embeddings-v2-small-en": {
                "path": "models/embeddings/jina-embeddings-v2-small-en",
                "Huggingface": "jinaai/jina-embeddings-v2-small-en"
            },
            "jina-embeddings-v2-base-en": {
                "path": "models/embeddings/jina-embeddings-v2-base-en",
                "Huggingface": "jinaai/jina-embeddings-v2-base-en"
            },
            "m3e-small": {
                "path": "models/embeddings/m3e-small",
                "Huggingface": "moka-ai/m3e-small"
            },
            "m3e-base": {
                "path": "models/embeddings/m3e-base",
                "Huggingface": "moka-ai/m3e-base"
            },
            "m3e-large": {
                "path": "models/embeddings/m3e-large",
                "Huggingface": "moka-ai/m3e-large"
            },
            "bge-small-en-v1.5": {
                "path": "models/embeddings/bge-small-en-v1.5",
                "Huggingface": "BAAI/bge-small-en-v1.5"
            },
            "bge-base-en-v1.5": {
                "path": "models/embeddings/bge-base-en-v1.5",
                "Huggingface": "BAAI/bge-base-en-v1.5"
            },
            "bge-large-en-v1.5": {
                "path": "models/embeddings/bge-large-en-v1.5",
                "Huggingface": "BAAI/bge-large-en-v1.5"
            },
            "text-embedding-ada-002": {
                "path": "",
                "apikey": "OPENAI_API_KEY"
            }
        },
        "VtoTModel": {
            "whisper-base": {
                "path": "models/voices/whisper-base",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-base"
            },
            "whisper-medium": {
                "path": "models/voices/whisper-medium",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-medium"
            },
            "whisper-large-v3": {
                "path": "models/voices/whisper-large-v3",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "openai/whisper-large-v3"
            },
            "faster-whisper-large-v3": {
                "path": "models/voices/faster-whisper-large-v3",
                "device": "gpu",
                "loadbits": 8,
                "Huggingface": "bababababooey/faster-whisper-large-v3"
            }
        },
        "TtoVModel": {
            "XTTS-v2": {
                "path": "models/voices/XTTS-v2",
                "device": "gpu",
                "loadbits": 16,
                "Huggingface": "coqui/XTTS-v2"
            }
        },
        "LocalModel": {
            "LLM Model": {
                "3B Model": {
                    "fastchat-t5-3b-v1.0": {
                        "path": "models/llm/fastchat-t5-3b-v1.0",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "lmsys/fastchat-t5-3b-v1.0"
                    }
                },
                "7B Model": {
                    "llama-2-7b-hf": {
                        "path": "models/llm/llama-2-7b-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "meta-llama/llama-2-7b-hf"
                    },
                    "llama-2-7b-chat-hf": {
                        "path": "models/llm/Llama-2-7b-chat-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "meta-llama/Llama-2-7b-chat-hf"
                    },
                    "chatglm2-6b": {
                        "path": "models/llm/chatglm2-6b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "THUDM/chatglm2-6b"
                    },
                    "chatglm2-6b-32k": {
                        "path": "models/llm/chatglm2-6b-32k",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "THUDM/chatglm2-6b-32k"
                    },
                    "chatglm3-6b": {
                        "path": "models/llm/chatglm3-6b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "THUDM/chatglm3-6b"
                    },
                    "tigerbot-7b-chat": {
                        "path": "models/llm/tigerbot-7b-chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "TigerResearch/tigerbot-7b-chat"
                    },
                    "openchat_3.5": {
                        "path": "models/llm/openchat_3.5",
                        "device": "cpu",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "openchat/openchat_3.5"
                    },
                    "Qwen-7B-Chat-Int4": {
                        "path": "models/llm/Qwen-7B-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "Qwen/Qwen-7B-Chat-Int4"
                    },
                    "fuyu-8b": {
                        "path": "models/llm/fuyu-8b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "adept/fuyu-8b"
                    },
                    "Yi-6B-Chat-4bits": {
                        "path": "models/llm/Yi-6B-Chat-4bits",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "01-ai/Yi-6B-Chat-4bits"
                    },
                    "neural-chat-7b-v3-1": {
                        "path": "models/llm/neural-chat-7b-v3-1",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "Intel/neural-chat-7b-v3-1"
                    },
                    "OpenHermes-2.5-Mistral-7B": {
                        "path": "models/llm/OpenHermes-2.5-Mistral-7B",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "teknium/OpenHermes-2.5-Mistral-7B"
                    }
                },
                "13B Model": {
                    "llama-2-13b-hf": {
                        "path": "models/llm/llama-2-13b-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "meta-llama/llama-2-13b-hf"
                    },
                    "llama-2-13b-chat-hf": {
                        "path": "models/llm/Llama-2-13b-chat-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "meta-llama/Llama-2-13b-chat-hf"
                    },
                    "tigerbot-13b-chat": {
                        "path": "models/llm/tigerbot-13b-chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "TigerResearch/tigerbot-13b-chat"
                    },
                    "Qwen-14B-Chat": {
                        "path": "models/llm/Qwen-14B-Chat",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 8,
                        "Huggingface": "Qwen/Qwen-14B-Chat"
                    },
                    "Qwen-14B-Chat-Int4": {
                        "path": "models/llm/Qwen-14B-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "Qwen/Qwen-14B-Chat-Int4"
                    }
                },
                "34B Model": {
                    "Yi-34B-Chat-4bits": {
                        "path": "models/llm/Yi-34B-Chat-4bits",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "01-ai/Yi-34B-Chat-4bits"
                    }
                },
                "70B Model": {
                    "llama-2-70b-hf": {
                        "path": "models/llm/llama-2-70b-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 8,
                        "loadbits": 8,
                        "Huggingface": "meta-llama/llama-2-70b-hf"
                    },
                    "llama-2-70b-chat-hf": {
                        "path": "models/llm/Llama-2-70b-chat-hf",
                        "device": "auto",
                        "maxmemory": 24,
                        "cputhreads": 8,
                        "loadbits": 8,
                        "Huggingface": "meta-llama/Llama-2-70b-chat-hf"
                    }
                }
            },
            "Multimodal Model": {
                "Vision Chat Model": {
                    "visualglm-6b": {
                        "path": "models/multimodal/image-chat/visualglm-6b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "THUDM/visualglm-6b"
                    },
                    "cogvlm-chat-hf": {
                        "path": "models/multimodal/image-chat/cogvlm-chat-hf",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "THUDM/cogvlm-chat-hf"
                    },
                    "mplug-owl2-llama2-7b": {
                        "path": "models/multimodal/image-chat/mplug-owl2-llama2-7b",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "MAGAer13/mplug-owl2-llama2-7b"
                    },
                    "Qwen-VL-Chat-Int4": {
                        "path": "models/multimodal/image-chat/Qwen-VL-Chat-Int4",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 4,
                        "Huggingface": "Qwen/Qwen-VL-Chat-Int4"
                    },
                    "internlm-xcomposer-7b-4bit": {
                        "path": "models/multimodal/image-chat/internlm-xcomposer-7b-4bit",
                        "device": "auto",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 4,
                        "Huggingface": "internlm/internlm-xcomposer-7b-4bit"
                    }
                },
                "Voice Chat Model": {},
                "Video Chat Model": {}
            },
            "Llamacpp(GGUF) Model": {
                "3B Model": {},
                "7B Model": {
                    "Yi-6B-Chat-gguf": {
                        "path": "models/llm/Yi-6B-Chat-GGUF",
                        "device": "cpu",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "TheBloke/Yi-6B-Chat-GGUF"
                    }
                },
                "13B Model": {},
                "34B Model": {
                    "Yi-34B-Chat-gguf": {
                        "path": "models/llm/Yi-34B-Chat-GGUF",
                        "device": "cpu",
                        "maxmemory": 20,
                        "cputhreads": 4,
                        "loadbits": 16,
                        "Huggingface": "TheBloke/Yi-34B-Chat-GGUF"
                    }
                },
                "70B Model": {}
            }
        }
    },
    "ServerConfig": {
        "default_host_ip": "127.0.0.1",
        "default_timeout": 300,
        "load_timeout": 120,
        "release_timeout": 60,
        "webui_server": {
            "host": "default_host_ip",
            "port": 8818
        },
        "fastchat_controller": {
            "host": "default_host_ip",
            "port": 20001,
            "dispatch_method": "shortest_queue"
        },
        "api_server": {
            "host": "default_host_ip",
            "port": 8819
        },
        "fastchat_openai_api": {
            "host": "default_host_ip",
            "port": 20000
        },
        "vtot_model_worker": {
            "host": "default_host_ip",
            "port": 20002,
            "device": "auto"
        },
        "ttov_model_worker": {
            "host": "default_host_ip",
            "port": 20003,
            "device": "auto"
        },
        "fastchat_model_worker": {
            "default": {
                "host": "default_host_ip",
                "port": 20010,
                "device": "auto",
                "vllm_enable": false
            }
        }
    },
    "ChatConfiguration": {
        "history_len": 5,
        "temperature": 0.7,
        "top_p": 0.9,
        "typical_p": 1.0,
        "top_a": 1.0,
        "tfs": 1.0,
        "epsilon_cutoff": 0.0,
        "eta_cutoff": 0.0,
        "diversity_penalty": 0.0,
        "no_repeat_ngram_size": 0,
        "do_samples": false,
        "tokens_length": {
            "cur": 1000,
            "min": 0,
            "max": 5000,
            "step": 10
        },
        "seed": {
            "cur": -1,
            "min": -1,
            "max": 1000
        },
        "top_k": {
            "cur": 50,
            "min": 0,
            "max": 200,
            "step": 1
        },
        "repetition_penalty": {
            "cur": 1.15,
            "min": 0.0,
            "max": 3.0,
            "step": 0.05
        },
        "encoder_repetition_penalty": {
            "cur": 1.15,
            "min": 0.0,
            "max": 3.0,
            "step": 0.05
        },
        "length_penalty": {
            "cur": 1,
            "min": 0,
            "max": 2,
            "step": 1
        },
        "guidance_scale": {
            "cur": 1,
            "min": 0,
            "max": 2,
            "step": 1
        }
    },
    "QuantizationConfiguration": {},
    "Fine-Tunning": {},
    "PromptTemplates": {}
}